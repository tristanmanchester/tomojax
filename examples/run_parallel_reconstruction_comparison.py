#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Parallel-beam 3D reconstruction comparison: clean vs misaligned projections
# - Assumes projections were generated by run_parallel_projector_misaligned.py
# - Memory-efficient: per-slice filtering and streaming backprojection (JAX scan)
# - Saves both reconstructions as TIFF for comparison

from __future__ import annotations

import argparse
import json
import math
import time
from pathlib import Path
from typing import Tuple

import jax
import jax.numpy as jnp
import numpy as np
import psutil
import tifffile as tiff


def get_memory_usage_mb() -> float:
    return psutil.Process().memory_info().rss / (1024 * 1024)


def tic() -> float:
    return time.time()


def toc(t0: float) -> float:
    return time.time() - t0


def create_ram_lak(n: int, pad_factor: int = 2) -> Tuple[np.ndarray, int, int]:
    """Create Ram-Lak filter in frequency domain with zero-padding."""
    n_pad = n * pad_factor
    f = np.fft.fftfreq(n_pad, d=1.0)  # cycles/sample in [-0.5, 0.5)
    H = np.abs(f).astype(np.float32)  # ramp
    start = (n_pad - n) // 2
    return H, n_pad, start


def filter_sinogram_ram_lak(
    sino: np.ndarray,  # (n_proj, nu)
    H: np.ndarray,
    n_pad: int,
    start: int,
) -> np.ndarray:
    """Filter sinogram across detector axis using Ram-Lak (per slice)."""
    n_proj, nu = sino.shape
    # Zero-pad along detector axis
    padded = np.zeros((n_proj, n_pad), dtype=np.float32)
    padded[:, start : start + nu] = sino
    # FFT, multiply ramp, IFFT
    F = np.fft.fft(padded, axis=1)
    F *= H[None, :]
    filtered_padded = np.fft.ifft(F, axis=1).real.astype(np.float32)
    # Extract central region
    filtered = filtered_padded[:, start : start + nu]
    return filtered


def build_xy_grids(nx: int, ny: int, vx: float, vy: float) -> Tuple[jnp.ndarray, jnp.ndarray]:
    """World-coordinate grids for (x, y) voxel centers, shape (ny, nx)."""
    x = (np.arange(nx, dtype=np.float32) - (nx / 2.0 - 0.5)) * vx
    y = (np.arange(ny, dtype=np.float32) - (ny / 2.0 - 0.5)) * vy
    X, Y = np.meshgrid(x, y, indexing="xy")  # (ny, nx)
    return jnp.asarray(X), jnp.asarray(Y)


@jax.jit
def backproject_slice_scan(
    filt_sino: jnp.ndarray,  # (n_proj, nu), filtered
    angles: jnp.ndarray,  # (n_proj,)
    X: jnp.ndarray,  # (ny, nx) world x
    Y: jnp.ndarray,  # (ny, nx) world y
    du: float,
    dtheta: float,
) -> jnp.ndarray:
    """
    Streaming backprojection for one z-slice:
    recon(x,y) = ∫ p_filt(phi, u=x cosφ + y sinφ) dφ
    """
    nu = filt_sino.shape[1]
    u_center = (nu / 2.0 - 0.5)

    def step(acc, i):
        phi = angles[i]
        row = filt_sino[i]  # (nu,)

        c, s = jnp.cos(phi), jnp.sin(phi)
        u = (X * c - Y * s) / du + u_center  # (ny, nx)

        u0 = jnp.floor(u).astype(jnp.int32)
        u1 = u0 + 1
        alpha = u - u0.astype(jnp.float32)

        # Valid mask for linear interpolation strictly inside detector
        mask = (u0 >= 0) & (u1 < nu)
        mask = mask.astype(jnp.float32)

        # Gather with clip, then zero-out with mask to avoid border replication
        u0c = jnp.clip(u0, 0, nu - 1)
        u1c = jnp.clip(u1, 0, nu - 1)
        v0 = row[u0c]  # (ny, nx)
        v1 = row[u1c]
        val = ((1.0 - alpha) * v0 + alpha * v1) * mask  # (ny, nx)

        return acc + val, None

    acc0 = jnp.zeros_like(X, dtype=jnp.float32)
    acc, _ = jax.lax.scan(step, acc0, jnp.arange(filt_sino.shape[0]))
    return acc * jnp.float32(dtheta)


def reconstruct_projections(
    projections: np.ndarray,
    angles: np.ndarray,
    nx: int, ny: int, nz: int,
    vx: float, vy: float, vz: float,
    nu: int, nv: int,
    du: float, dv: float,
    H: np.ndarray,
    n_pad: int,
    start: int,
    X: jnp.ndarray,
    Y: jnp.ndarray,
    projection_type: str
) -> np.ndarray:
    """Reconstruct a volume from projections."""
    n_proj = projections.shape[0]
    
    # Estimate dtheta (assume near-uniform)
    diffs = np.diff(angles)
    dtheta = float(np.mean(diffs))
    
    # Reconstruction volume (z, y, x) to match TIFF stack convention
    recon = np.zeros((nz, ny, nx), dtype=np.float32)
    
    t_total = tic()
    peak_mb = get_memory_usage_mb()
    
    # Process each z-slice independently
    n_slices = min(nv, nz)
    print(f"Reconstructing {projection_type} projections: {n_slices} z-slices ...")
    
    for z_idx in range(n_slices):
        t0 = tic()
        sino = projections[:, z_idx, :]  # (n_proj, nu)
        # Filter (NumPy)
        sino_f = filter_sinogram_ram_lak(sino, H, n_pad, start)  # (n_proj, nu)
        # Backproject (JAX)
        slice_recon = backproject_slice_scan(
            jnp.asarray(sino_f),
            jnp.asarray(angles),
            X,
            Y,
            du,
            dtheta,
        )
        slice_np = np.asarray(jax.block_until_ready(slice_recon))
        recon[z_idx] = slice_np  # (y, x)
        
        dt = toc(t0)
        curr_mb = get_memory_usage_mb()
        peak_mb = max(peak_mb, curr_mb)
        if (z_idx + 1) % max(1, n_slices // 20) == 0 or (z_idx + 1) == n_slices:
            print(
                f"  {projection_type} z {z_idx+1:4d}/{n_slices} | time={dt:.3f} s | RSS={curr_mb:.1f} MB"
            )
    
    t_recon = toc(t_total)
    print(f"{projection_type} reconstruction complete:")
    print(
        f"  stats: min={recon.min():.4f} max={recon.max():.4f} "
        f"mean={recon.mean():.4f} std={recon.std():.4f}"
    )
    print(f"  time: {t_recon:.2f} s | per-slice: {t_recon/max(1,n_slices):.3f} s")
    print()
    
    return recon


def main():
    parser = argparse.ArgumentParser(
        description="Parallel-beam 3D FBP reconstruction comparison (clean vs misaligned)"
    )
    parser.add_argument(
        "--input-dir",
        type=str,
        default="parallel_proj_misaligned",
        help="Directory containing projections_clean.tiff, projections_misaligned.tiff, etc.",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="parallel_recon_comparison",
        help="Directory to save reconstructions",
    )
    parser.add_argument(
        "--nu-pad-factor", type=int, default=2, help="Zero-padding factor along detector axis"
    )
    parser.add_argument(
        "--angle-step",
        type=int,
        default=1,
        help="Use every k-th angle for faster recon (k=1 means use all)",
    )
    args = parser.parse_args()

    in_dir = Path(args.input_dir)
    out_dir = Path(args.output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    print("=== Parallel-beam 3D FBP Reconstruction Comparison ===")
    print(f"Input:  {in_dir}")
    print(f"Output: {out_dir}")
    print(f"Device: {jax.devices()[0]}")
    print(f"Initial RSS memory: {get_memory_usage_mb():.1f} MB")
    print()

    # Load metadata and angles
    with open(in_dir / "metadata.json", "r") as f:
        meta = json.load(f)
    grid = meta["grid"]
    det = meta["detector"]

    nx, ny, nz = int(grid["nx"]), int(grid["ny"]), int(grid["nz"])
    vx, vy, vz = float(grid["vx"]), float(grid["vy"]), float(grid["vz"])
    nu, nv = int(det["nu"]), int(det["nv"])
    du, dv = float(det["du"]), float(det["dv"])

    print(
        f"Volume grid: {nx} x {ny} x {nz} | vox = ({vx:.3f}, {vy:.3f}, {vz:.3f})"
    )
    print(f"Detector: {nu} x {nv} | pix = ({du:.3f}, {dv:.3f})")

    angles = np.load(in_dir / "angles.npy").astype(np.float32)
    
    # Check what projection files exist
    clean_path = in_dir / "projections_clean.tiff"
    misaligned_path = in_dir / "projections_misaligned.tiff"
    noisy_path = in_dir / "projections_noisy.tiff"
    
    projection_files = []
    if clean_path.exists():
        projection_files.append(("clean", clean_path))
    if misaligned_path.exists():
        projection_files.append(("misaligned", misaligned_path))
    if noisy_path.exists():
        projection_files.append(("noisy", noisy_path))
    
    if not projection_files:
        print("Error: No projection files found! Expected projections_clean.tiff and/or projections_misaligned.tiff")
        return
    
    print(f"Found projection files: {[name for name, _ in projection_files]}")
    print()

    # Optionally sub-sample angles for speed
    if args.angle_step > 1:
        angles = angles[:: args.angle_step]
        print(f"Subsampled angles by {args.angle_step}: {len(angles)} angles")

    # Prepare filter (shared across all reconstructions)
    H, n_pad, start = create_ram_lak(nu, pad_factor=args.nu_pad_factor)
    print(f"Ram-Lak filter: nu_pad={n_pad}, extract [{start}:{start+nu}]")

    # Prepare XY grids (reused for all slices and reconstructions)
    X, Y = build_xy_grids(nx, ny, vx, vy)  # (ny, nx) each
    print(f"Built XY grids: {X.shape}")

    # Warm-up JIT with a tiny dummy slice
    n_angles_used = len(angles)
    dummy_sino = jnp.zeros((max(1, min(8, n_angles_used)), nu), dtype=jnp.float32)
    dummy_angles = jnp.asarray(angles[: dummy_sino.shape[0]])
    _ = backproject_slice_scan(dummy_sino, dummy_angles, X, Y, du, dtheta=0.01)
    jax.block_until_ready(_)
    print(f"JIT warmup done. RSS={get_memory_usage_mb():.1f} MB")
    print()

    # Process each projection type
    reconstructions = {}
    for proj_type, proj_path in projection_files:
        print(f"Loading {proj_type} projections from {proj_path}")
        projections = tiff.imread(proj_path)  # (n_proj, nv, nu)
        
        # Apply angle subsampling to projections
        if args.angle_step > 1:
            projections = projections[:: args.angle_step, :, :]
        
        print(f"Projections shape: {projections.shape} | RSS={get_memory_usage_mb():.1f} MB")
        assert projections.shape[2] == nu and projections.shape[1] == nv
        
        # Reconstruct
        recon = reconstruct_projections(
            projections, angles, nx, ny, nz, vx, vy, vz, nu, nv, du, dv,
            H, n_pad, start, X, Y, proj_type
        )
        
        # Save reconstruction
        out_tiff = out_dir / f"reconstruction_fbp_{proj_type}.tiff"
        tiff.imwrite(str(out_tiff), recon.astype(np.float32))
        print(f"Saved {proj_type} reconstruction: {out_tiff}")
        print()
        
        reconstructions[proj_type] = recon

    # Compute and display comparison statistics
    if "clean" in reconstructions and "misaligned" in reconstructions:
        clean_recon = reconstructions["clean"]
        misaligned_recon = reconstructions["misaligned"]
        
        # Compute difference
        diff = clean_recon - misaligned_recon
        mse = np.mean(diff**2)
        rmse = np.sqrt(mse)
        psnr = 20 * np.log10(clean_recon.max()) - 20 * np.log10(rmse) if rmse > 0 else float('inf')
        
        print("=== Reconstruction Comparison ===")
        print(f"Clean reconstruction:")
        print(f"  min={clean_recon.min():.4f} max={clean_recon.max():.4f} mean={clean_recon.mean():.4f}")
        print(f"Misaligned reconstruction:")
        print(f"  min={misaligned_recon.min():.4f} max={misaligned_recon.max():.4f} mean={misaligned_recon.mean():.4f}")
        print(f"Difference (clean - misaligned):")
        print(f"  min={diff.min():.4f} max={diff.max():.4f} mean={diff.mean():.4f}")
        print(f"Quality metrics:")
        print(f"  MSE = {mse:.6f}")
        print(f"  RMSE = {rmse:.6f}")
        print(f"  PSNR = {psnr:.2f} dB")
        
        # Save difference volume
        diff_path = out_dir / "reconstruction_difference.tiff"
        tiff.imwrite(str(diff_path), diff.astype(np.float32))
        print(f"Saved difference volume: {diff_path}")

    # Save metadata
    meta_out = {
        "method": "parallel_fbp_ram-lak_comparison",
        "input_dir": str(in_dir),
        "output_dir": str(out_dir),
        "grid": {"nx": nx, "ny": ny, "nz": nz, "vx": vx, "vy": vy, "vz": vz},
        "detector": {"nu": nu, "nv": nv, "du": du, "dv": dv},
        "angles": {
            "count": len(angles),
            "angle_step": args.angle_step,
        },
        "filter": {"type": "ram-lak", "nu_pad_factor": args.nu_pad_factor},
        "reconstructions": list(reconstructions.keys()),
        "memory": {
            "final_rss_mb": get_memory_usage_mb(),
        },
        "device": str(jax.devices()[0]),
    }
    
    # Add comparison metrics if available
    if "clean" in reconstructions and "misaligned" in reconstructions:
        meta_out["comparison"] = {
            "mse": float(mse),
            "rmse": float(rmse),
            "psnr_db": float(psnr)
        }
    
    with open(out_dir / "metadata.json", "w") as f:
        json.dump(meta_out, f, indent=2)

    print(f"\nFinal RSS memory: {get_memory_usage_mb():.1f} MB")
    print("Done.")


if __name__ == "__main__":
    main()